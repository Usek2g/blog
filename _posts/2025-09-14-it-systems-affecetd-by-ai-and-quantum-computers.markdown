---
layout: post
title:  "AI・量子コンピュータにかかわるリスク管理"
date:   2025-09-14 10:20:27 +0900
categories: bookreview
img: it-systems-affecetd-by-ai-and-quantum-computers.jpg # Add image post (optional)
tags: [security] # add tag
description: 最新テクノロジー量子コンピュータとAIが新たなセキュリティリスクを生み出す
---

テクノロジーの進化はすさまじいスピードです。特に、スマートフォン以来の社会を大きく変革するテクノロジーとされるAI。ものすごいお金が投入されており、各社、凄まじいスピードで新バージョン、新サービスを公開しています。なにより検索の王者であるGoogleが検索を捨てるかのようにLLMに全振りしているとこからも、彼らの危機感と本気度がうかがえます。
また、AIに比べるとあまり聞かれない用語ですが「量子コンピュータ」というものがあります。従来のコンピューターとは全く異なる原理で動く、次世代のコンピューターです。従来のコンピューターが「ビット」を使って情報を「0」か「1」のどちらかで表現するのに対し、量子コンピューターは「量子ビット」という単位で情報を扱います。量子ビットは、「0」と「1」の両方の状態を同時に持つことができます。例えるなら、コインが表と裏の両方を同時に向いているような状態です。n個の量子ビットがあれば、2のn乗通りの状態を同時に表現できるため、膨大な情報を一度に処理できます。量子コンピュータは従来のスーパーコンピューターでも膨大な時間がかかるのに比べて、はるかに高速に解くことができるとされています。
この２つの最新テクノロジーが、セキュリティに対してどのようなリスクがあり、どう対応していくべきか、について書かれた本が本書になります。海外の本の翻訳ではないのですが、非常に分厚く濃密な力作です。読むのがたいへんでした。

前半は量子コンピュータ。量子コンピュータはAIと異なり現状誰もが利用できるものではありません。ハイスペックなコンピュータが必要なのはもちろん、絶対零度に近い環境で制御する必要があり、エラーの訂正技術も必要となります。しかしこれらの課題が克服された量子コンピュータ、これを"CRQC"(「Cryptographically Relevant Quantum Computer」の略で、日本語では「暗号解読関連量子コンピューター」と訳されます）と呼びますが、CRQCが登場した場合は、従来のコンピューターでは事実上不可能だった、現在の公開鍵暗号を現実的な時間で復号できてしまうという、現在のサイバー空間の前提を崩してしまう可能性があるとされています。
また、Googleが「2029年までに商用利用可能な規模の量子コンピュータの開発を目指している」とのことです。この本では世界各国がCRQCについて調査を行っていることが解説されており、おおよそ2035年前後にCRQCが登場し、それによる暗号解読のリスクを考慮し、備える必要があるとのことです。

この本で紹介されていた「ハーベスト攻撃」というものが勉強になりました。現在の技術では復号できない暗号化されたデータを今のうちに詐取して、来るべきCRQCの登場まで保管しておき、CRQCの登場で一気に復号化するという攻撃です。昨今のセキュリティインシデントで「漏洩した情報・紛失したＰＣの情報は暗号化されているのでリスクは低い」というアナウンスを聞きますが、これが未来の時限爆弾になってしまうという恐ろしい攻撃です。

また、情報資産台帳で『このデータは暗号化されているのでリスクは低い』と定義づけしていた情報が軒並み見直しを迫られるため、セキュリティ対応の工数の増加が考えられます。追加の対策として"クリプトインベントリ"=対象の資産・システムで利用されている暗号の使用状況やアルゴリズムもまたきちんと管理しておき、CRQCに対して対策ができているのか、という管理が必要になることが提示されていました。
防御側も何もしていないわけではなく、PQC (Post-Quantum Cryptography) アルゴリズムという、量子コンピュータに対して耐性を持つアルゴリズムが2024年にNISTによって標準化されました。こちらの導入が先進的な企業では進んできており、我々末端の会社も順次この暗号システムに置き換えていくことになりそうです。とはいえ生まれたばかりのPQCは信頼性や実績という点でまだまだ問題を抱えているため、既存の暗号化アルゴリズムとのハイブリット暗号が現状は想定されています。
世界の政府や金融機関にとっては量子コンピュータによる暗号の無効化は非常に重要な話しです。ただこれは普通の企業でセキュリティ対応をしている自分の希望的推測ですが、証券会社の不正アクセスに伴う多要素認証のように、複数の実害が生じたタイミングで、社会が一斉に「うわああ、やらないと！」という空気になると思うのですよね。その際にこの本のような話を知っておけば、「聞いてないよ！」とはならず、粛々と対応することができます。この本の各章末には"ワーク"とう、自分の組織でやるべきリスク管理が列挙されているのですが、いったんは今すぐ何かをするということはせず、頭の片隅に入れておこうと思います。

後半はAIについて。AI（とその背後にあるLLM）のセキュリティリスクについては様々なことが想定されます。
- 入力した内容が漏洩するセキュリティのリスク
- AIに特定の用語を問い合わせることで、機密情報やデータを抽出する
- AIのデータソースに不正アクセスされ、ウソが注入（ポイズニング）された結果、利用者が騙されてしまうリスク。データソースではなく、モデル自体が改ざんされる危険性も
- AIによるアウトプットの誤り（バイアス、ハルシネーション、ディープフェイクなど）

この本には書かれていませんでしたが、最近僕が感じるのは **「自分でなにも考えずすぐAIに放り込んで、結果をそのまま返してしまう人間としての退化というリスク」** があると考えています（自戒）

こちらについても量子コンピュータ同様、国際社会が連携して、ロボット三原則をAIに当てはめたような[トラストワージネス](https://www.biprogy.com/com/tech/technology_foresight/back_number/2021/02-5.html)が提唱されていたり、法律やガイドラインの策定が進んでいます。ただ、AIの進化があまりに早いので、なかなか人の対応が追い付いていない現状と思います。しかしこの手のガイドラインの評議会にはバチカンもオブザーバーで参加しているのですね。彼らはどう思っているのでしょうか？AIは自動車やコンピュータといった歴史上私たちの生活を変えたテクノロジーとは根本的に違うと思います。それらのテクノロジーは人間が主、人間が扱うものでしたが、AIに至っては人間を超える、むしろAIの"啓示"に従い、人間が作業をしているまであります。もしかしたらバチカン内でもそういうのを踏まえたコンクラーベが行われていたのかも、と読んでいて思いました。

国際社会が様々なルールを作り、LLM提供者側に課している一方、僕たちAI利用者が対応できるセキュリティリスクについても説明されています。[NIST AIリスク管理フレームワーク](https://www.pwc.com/jp/ja/knowledge/column/awareness-cyber-security/generative-ai-regulation04.html)はNISTが2023年1月に発行した、信頼できるAIシステムの開発、導入、利用を支援するための自主的なリスク管理に関するフレームワークです。このフレームワークについて何を実施するかを詳細に解説しています。

- 統制（Govern）：AIに対するリスク管理・文書化する。他3つのコアにまたがる
- 位置づけ（Mapping）：、利用するAIの分類を行い、利益とコストを明確にし、潜在的リスクによる損失も明確にする。特にAIに対して人間が監督するプロセスを定義する
- 測定（Meatsure）：運用前、運用後も効果を測定する。トラストワージネスを満たしているかについても定期チェック
- 管理（Management）：位置づけ、評価分析したうえでリスクマネジメントを行う

この4つのコア機能に対して、各コア機能がカテゴリーとサブカテゴリーがあるのですが、これが長文で。書いてあること1つ1つは正しく、理解できるのですが、これらを業務で利用しているAIという情報資産に対してチェック、実施するのはとても出来ない、というのが僕の感想です。AIはもはやビジネスに不可欠な存在なので、AI用のリスク管理フレームワークを利用せよ、というのは納得ですが、まずは既存のリスク管理フレームワークに相乗りさせる形で許してもらえないものか。いや、許してもらえるはず。セキュリティも100%を目指すよりも、最低限を満たすだけでまずは世の中の平均以上の対応になるので。

「セキュリティの終わりのない道」というタイトルのブログですが、セキュリティはこの本が紹介しているような新テクノロジーに対しても対応しないといけません。本当に終わりがありませんね…。
